# Trap的代理机制

通常状态下，事件发生时都是直接陷入到最高特权级的M态，但是很多时候没必要直接上报到最高领导那里去对吧，通常的思路是，U态遇到处理不了的问题了，就抛给S态去处理，S态要是还处理不了，再找M态去解决。

通常情况下，一般默认调用ECALL(用于在特权态之间切换)的时候，都是无条件转到M态的，但是通过设置medeleg、mideleg两个寄存器，可以实现在U态执行ECALL的时候进入S态，在S态执行ECALL的时候进入M态。

# 定时器、性能计数器相关

+ 关于mepc、sepc的设置，中断指令，通常不用重试指令，处理完成中断以后直接回到原来的位置接着执行即可，所以mepc、sepc的值在发生中断时，会被设置为下一条需要执行的指令。而对于异常，通常需要重试，例如在执行访存操作的时候发生了内存缺页异常，这个时候需要陷入到内核中，调整页表，从特权态返回之后再回来重新执行一次这条触发了异常的访存指令，因此对于同步异常，mepc指向导致异常的指令，而不是导致异常的指令的下一条指令。

+ mstatus、sstatus寄存器里面会保留特权态切换之前的中断、特权级记录一下，用于后面恢复特权态的时候恢复原来的状态。

+ 这里提到了一个新的CSR叫做mscratch，并且列举了一个比较抽象的使用方法，这个寄存器可以在发生特权态切换的时候传递一些数据，这个在实验的trap模块的汇编代码中有所体现。如果这里看不懂，可以结合实验指导书进行学习。


# 虚拟内存、页表相关的基础知识复习

先看几个例子：

+ 第一个例子：假设我们编写了一个程序，然后在我们熟悉的Windows、linux或OsX系统上运行这个程序，假设我们把这个程序同时启动了N次(N>1), 那么这N个程序，每个程序在运行的时候都会对自己的代码中定义的变量进行读写，那么，这几个程序是一样的，他们各自操作自己的变量，会不会造成数据的冲突呢？

+ 第二个例子：我们知道在Linux上面有一个fork系统调用，可以创建一个进程的副本，但是我们希望这个创建副本的过程应该尽可能高效，所以并不会把父进程所拥有的内存完全复制给子进程，而是只复制必要的数据，剩余的绝大部分数据通过写时复制（Copy On Write， COW）的方式，先在父子进程之间共享，只要大家都不修改共享的内存，只是读取，那么就可以一直共享下去，如果一个进程要写内存的时候，再把他要写的内存复制一下，变成进程私有的。这是怎么做到的？


+ 第三个例子：Linux上还有一个叫做mmap的系统调用，可以把硬盘上的一个文件映射到内存地址上，这个时候访问内存地址就能够读写磁盘上的文件，就不再需要通过read()或者write()这样的调用来读写文件了。这又是怎么做到的？

所有上面这些酷炫的功能，都是通过虚拟内存技术来实现的。所谓虚拟内存，就是把虚拟地址空间映射到实际的物理内存地址空间上面去。

啥叫虚拟地址空间？就是让每一个进程都认为自己拥有整个世界。比如你的处理器是32位的，那每一个进程就都认为自己有4GB的内存空间可以使用，对应内存地址0x00000000到0xFFFFFFFF。如果是64位的处理器呢，64位对应着16384 PB的内存大小，就是说每一个进程都认为自己有16384 PB的内存可以使用。这是一个非常巨大的数值，但是回忆一下上次课程中我们提到过Sv39、Sv48这些名词，它表示在RISC-V处理器上，实际的虚拟地址空间没有64bit那么大，如果你选用了Sv39，那就是每个虚拟地址空间由39个bit组成，也就是512GB的内存空间。

那啥又叫物理内存地址空间呢？物理地址空间就是你真实世界中物理内存的大小。比如你是一个32位的系统，但是你只有1GB的内存条，那么你就并没有把所有的内存地址空间用完，你的物理内存地址范围就是0x00000000~0x3FFFFFFF。当然，这里也要说一下，实际分配给内存条的物理地址空间也不一定是从0x00000000开始的，可能有一个偏移量，还是以1GB的内存条为例，你的物理内存地址空间可能是0x10000000~0x4FFFFFFF,不管怎样，这个地址空间首尾地址的差值肯定是1GB，就是你实际物理内存条的存储容量。

下一个问题，如果每个进程都认为自己有很大的内存可以用，但是实际的物理内存是有限的，那所有的应用都说给我4GB内存，这可咋办？回忆我们上一课在将特权级架构的时候，PPT一开始就提到了为什么需要特权级架构？其中一个原因是我们要管理共享资源，内存空间就是一种共享资源，所以我们需要操作系统来给各个应用程序的进程分配内存。通常情况下，一个应用程序启动的时候只需要很小的内存，后续需要更多内存的时候会通过诸如malloc之类的方法找操作系统分配堆内存，如果要申请内存的时候操作系统手里也没货了，那么就会出现Out Of Memory（OOM）的错误。所以这里有一个很重要的点：虽然虚拟内存地址空间很大，但是通常应用程序只会用到其中很小的一部分。但是呢，应用程序在使用虚拟地址空间的时候，不一定是连续使用的，一个应用完全可以说我在虚拟地址空间的最开始和最末尾分别申请1个字节的内存来用。这个时候，虽然应用程序只申请了很少的内存，但是他所使用的地址空间跨度是很大的，换句话说，在虚拟地址空间中可以有很多的没有使用的空洞。

上面已经大致解释了一些名词和使用场景，接下来看看操作系统要是想管理内存分配，具体是怎么实现这些功能的。为了后面的介绍方便，我们把虚拟内存地址简称为VA（Virtual Address），把物理地址简称为PA（Physical Address）。

VA和PA之间的关系，实际就是一个映射关系，我们可以通过查表的方式来实现这个映射。例如某一个进程说，我要申请0x1000（4kB）大小的一块内存，放在以VA 0x10000000作为开始的地方，然后再申请一块0x2000(8kB)大小的一块内存，放在以VA 0x50000000开始的地方。操作系统收到这两个内存分配请求以后，先翻翻自己的账本，看看有没有足够的内存，如果发现没有了，直接返回OOM错误给用户进程。如果自己还有存货，假设操作系统知道在PA为0x12340000和0x43210000两个位置都还有空间，于是就可以建立一个映射表：


|VA|	PA|	Size|
|---|---|---|
|0x10000000	|0x12340000|	0x1000|
|0x50000000|	0x43210000|	0x2000|


这样，比如说应用程序想读取VA 0x50000010地址上的数据，那么经过查表可以发现，首先这个VA在映射表中是存在的，因为他位于0x50000000~0x50000000+0x2000这个区间内，所以就可以把这个读取操作映射到对物理内存地址0x43210010的操作。如果应用想读取VA 0x50003010地址上的数据呢？由于这个访问超出了映射表里记录的范围，所以会被驳回。

因为每一个用户进程都认为自己拥有整个VA空间，所以每个进程都有自己的一份映射表。在一个CPU核心上，同一时刻只能执行一个进程对吧，所以操作系统在切换进程的时候，也需要切换不同的映射表。运行A进程的时候，按照A进程的映射表进行翻译，运行B进程的时候，按照B进程的映射表进行翻译。

这里再强调一点，用户进程是感知不到PA存在的，它们就活在VA的世界里（除非操作系统给他开了个口子，让他可以查询到自己世界里的VA对应的PA是什么），而操作系统因为运行在比用户应用高的特权级里面，所以操作系统是上帝视角，它既能看到物理地址，也能看到每一个进程的VA是如何映射到PA的。

好了，已经了解了内存地址映射的基本思路了，接下来就看看怎么具体实现这个查表的过程吧。因为VA中每一个对内存的读写操作都需要经过地址翻译才能找到真正的PA，所以这个过程必须快。想快的话，有两个优化方向：

+ 让硬件自动去完成查表和转换
+ 优化列表的存储数据结构，加速查找

因为我们就是想快，越快越好，所以这两种手段我们都要用。其中硬件查表这件事，就是通过引入一个叫做MMU的硬件电路来实现的。而为了让MMU也能够查的更快，我们也需要给MMU提供一种更加优化的数据格式。关于MMU这个硬件咱们后面再说，先看看数据结构的问题。

首先来思考一个问题，这个内存地址转换的最小单位是什么，或者说上面的表格里，size一列最小可以是多少。这个地方需要考虑的是映射表和实际可用内存之间的关系，如果映射粒度太细，那么可能内存里绝大部分的空间都用去存储映射表了，这就本末倒置了。举个例子，假设极端情况，我们允许以1个字节为单位进行映射，还是以32位系统举例，为了映射每1个字节，映射表里都需要存储VA、PA、Size，总共4*3=12个字节，也就是说，假设我想映射1GB的内存地址空间，那么要占用额外的12GB内存空间用来存储映射表。是不是有点过分了？

所以呢，大家就想了一个方法，咱们定义一个叫做页的概念，通常每个页的大小是4kB，这是一个通用的大小，也有些系统使用了比4kB大很多的页面，叫做巨页。我们只关心4kB的标准页大小。然后呢，我们之前的映射表里，最小的映射单位就是页了，所以这个映射表也被称作页表（page table）.然后表格的每一行称之为一个页表项（Page Table Entry, PTE）

先来看最简单暴力的页表存储方法：我们可以根据VA的地址从小到大排列这个表，然后在检索这个表的时候，只需要进行二分查找，就可以找到对应的页表项。算法的复杂度是O(LogN)。

我们想再快一点，能不能做到O(1)的时间复杂度呢？按照空间换时间的思路，可以这样来做。我们要求每一条页表项里面的映射关系只能代表4kB大小的页面，也就是说，每4kB的内存，就要对应一个页表项。哪怕是连续的内存地址，也不能用一个PTE来记录，例如我有12kB连续的内存空间，那么必须要3个PTE分别记录每个4kB页面的映射关系。另外一点是，我们要一次性把整个虚拟地址空间都建好映射关系，这样带来了两个好处：

+ 首先，因为每个页表项都是4kB大，所以我们最初的页表里面，第三列就不需要了。
+ 其次，因为我们把整个地址空间都提前建立好了映射关系，也就是说从第0个4kB页面到最后一个4kB页面，我们都有对应的页表项，并且这些页表项自然就是排好顺序的，像是一个大数组。对于任何一个要访问的VA，我们只需要除以4096字节（也就是4kB，一个页面的大小），就可以得到这个VA所对应的页表项在数组里面的下标。我们知道对数组的下标访问时间复杂度是O(1)的，完美符合我们的要求，并且除以4096这件事，可以通过右移12位的位运算来实现，所以实现起来也很高效很简便。另外还有一点，我们最原始映射表里面的第一列是VA，但现在VA这一列可以由数组的下标来表示了，因此，我们的PTE就变成了一个只有4字节的条目。

这里再说的细一点，还是假设我们32bit机器，4GB的VA地址空间，这4GB包含1M个4kB的页，所以我们要申请一个长度是1024*1024的大数组，这个数组的每一个元素都是一个32bit的PA地址，这个PA地址指向一个4kB页的起始位置，所以我们整个页表项会占用1M * 4B = 4MB的内存空间。

当我们假设要访问VA=0x12345678这个地址的时候，我们就首先把这个地址右移12bit，得到了0x00012345这个下标，于是我们就可以按照下标找到页表数组里面第0x00012345个元素，把这个元素的值取出来，就是这个VA所对应的PA的页面的起始地址，假设这个PTE里面存储的是0xAABBC000(注意这个PA的后三位一定是0，因为PTE中存储的是每个4kB页面的起始地址，所以他一定是4kB对齐的)。然后取出我们要访问的VA的后12个bit,这12个bit就是这个地址相对于这个4kB页面起始地址的偏移量，在我们的例子中，后12个bit用16进制表示就是0x00000678。好了，把偏移量和物理页起始地址相加，得到 0xAABBC000 + 0x00000678 = 0xAABBC678，那么我们就完成了VA到PA的映射，从VA=0x12345678映射到了PA=0xAABBC678。

整个转换过程基本上就是位运算，所以非常适合用组合数字电路来实现。


看起来挺美好的，但是问题也不少，主要问题在于占用的空间。我们是预分配了整个虚拟地址空间的映射关系，咱们上面的例子是32bit的虚拟地址空间，每个页表要占用4MB的内存。那如果是我们之前提到的Sv39呢？如果给Sv39预先分配页表的话，那就得占用512MB的内存空间，而且这还只是1个进程的页表项，你要是开10个进程呢？不好意思，5个GB的内存已经被页表吃掉了。

你可能会说，不是所有的进程都会使用完整的内存空间啊，确实，但是回忆我们刚才说过的，虚拟地址空间里面可以有很多的空洞，一个进程想使用地址空间的最后一个字节是合理的。于是这个问题就变成了一个如何高效实现稀疏数组存储的问题了。


我们面对的问题是如何存储稀疏的地址，那么，什么是地址？北京市海淀区双清路30号是清华大学的地址，计算机世界的地址和我们生活中的地址有什么共性吗？看到生活中的地址，我们很自然的会想到北京市/海淀区/双清路30号。这是一个分级的表达方式，那么对于计算机中的地址呢，也是类似的，地址是一个无符号整数，对于它来说，越高的比特位代表了越大的内存地址范围。


```

北京市(00)
  |--朝阳区(00)
      |--建国路(1001)
  |--海淀区(01)
  |--昌平区(10)
      |--育知东路(1001)
  |--西城区(11)
      |--南礼士路(1001)
天津市(01)
  |--和平区(01)
  |--北辰区(10)
上海市(10)
  |--黄埔区(11)
重庆市(11)

```

回到我们的页表存储上来。我们还是以32bit系统为例，假设有一个地址是0x12345678,它对应的2进制表达是0b00010010001101000101011001111000,如果我们把这个地址给做一下分段，变成这个样子：

0b0001001000_1101000101_011001111000

可以看到，我们把一个32bit的地址分成了10 + 10 + 12这样的三段。我们可以把这三段分别类比成上面的城市、行政区、街道三级。先看第一段，由10个bit组成。这10个bit正好可以表示1024，也就是1k，类比到上面的例子里，就是我们可以编码1k个不同的城市。所以说通过高10bit，我们可以首先锁定城市。接下来我们就要顺着城市再去找城市里面的行政区。

这里可以看做在第一级中，只有一个集合，这个集合里面每一个元素都是城市。第二级里面，最多可以有1024个集合，每个集合里面又可以有最多1024个元素，这些第二级的集合元素分别是某一个城市里面的行政区。

那么，当我们给定一个城市以后，肯定要顺着某些指示找到第二级中对应的集合。顺着某个东西找到另一个东西，这句话翻译到计算机里面不就是指针么。现在我们就可以从城市类比到页表上了。

我们知道一个页是4kB大小，32位系统里面一个指针是4字节，那么一个内存页恰好可以存储1k个指针。那我们选定一个内存页作为我们的一级页表，这个一级页表的大小就是4kB，并且只有一个一级页表，里面包含了1024个指针，这些指针指向什么呢？指向二级页表。

那么二级页表又是什么样的呢？首先，我们有1024个二级页表（因为一级页表中的每个指针都指向一个二级页表），每一个二级页表的大小也是4kB,所以每个也表内也有1024个条目，这样在第二级，我们就有了1024 * 1024 = 1M个条目。到这里有个区别了，我们假设这棵树只有两层深，那么一级页表中的每一个条目是一个指向二级页表的指针，而二级页表中的每一个条目所存储的内容就是一个物理页的起始地址。这句话换个说法就是，非叶子节点存储的是指向下一级的指针，而叶子结点存储的是一个物理页的地址（也可以理解为指向物理页的指针）。

我们还是回到刚才提到的这个地址：0b0001001000_1101000101_011001111000

怎么查这个页表呢？先把第一段0b0001001000拿出来，根据他可以在一级页表的1024个元素中，根据数组下标，直接找到一个对应的条目，这个条目里存储的是另一个4kB页面的地址，这个新4kB页面里面又有1024个条目，我们根据第二段0b1101000101,又可以在这个页面里面找到一个元素，于是我们可以把这个元素的值取出来，假设这个元素里存储的内容是0xAABBC000,这个就是物理地址空间中一个4kB页面的起始地址，然后我们再把VA中第三段0b011001111000和0xAABBC000相加，就可以得到0xAABBC678。可以看到第三段地址的宽度是12bit，正好可以表示4096个字节在一个4kB页面中的偏移量。这样就实现了一个通过二级查表的方式，完成了从VA到PA的转换。


我们来对比一下这种方式和上一种方式的异同之处：

虽然我们查了两次表，但是从时间复杂度上来说，这是一个常数级别的操作，所以仍然是O(1)，满足我们的要求
由于是树状结构，如果某些二级页表对应的VA从来没有使用过，那么这一部分对应的二级页表就可以不存储。等到二级页表某个地方真的要用到的时候，只需要在物理内存中随便找一块空闲的4kB大小的空间，再在一级页表中指向这一块空间即可。这就相当于我们的页表存储其实是可以高效的插入和删除的，没必要一开始全部都分配好。后期可以按需不断膨胀。
以上这种10+10+12的地址划分方式呢，就是Sv32所采用的划分方式。了解为Sv32之后，我们再来看看Sv39，用Sv39再来加深一下对页表概念的理解。

注意到，Sv32一定是在32位的处理器架构上的，所以其指针大小都是4字节，而Sv39一定是运行在64位架构的处理器上的，所以对于SV39而言，每个页表项就不是4字节了，而是8字节。所以，一个4kB的内存页，就只能存放512个PTE了。那么512只需要用9个比特位就可以表示，所以在Sv39地址空间方案中，39bit的VA是按照9+9+9+12的方案来划分的，同理，Sv48采用的是9+9+9+9+12的方案，Sv57采用的是9+9+9+9+9+12的划分。

那么同样可以得出，对于Sv39来说，我们需要3级页表，对于Sv48来说，就需要4级页表，而对于Sv57来说，自然就是5级页表了。 详情可以参考特权级架构手册。


有一个在Sv32模式下的VA地址划分图，就体现了我们10+10+12的划分方式，其中高20位被称为虚拟页号(virtual page number, VPN)，而这个VPN又被划分为两级，分别叫做VPN[1]和VPN[0]，然后地址的低12位被称作页内偏移（page offset）。

再次仔细体会一下分页、页内偏移这些概念，基于二进制地址做一些数学游戏，就可以把一个32bit的二进制数划分为不同的区段。假设我们让低12bit全部为0，那么高20bit的任一组合就可以形成类似0xXXXXX000这样的地址，这样的地址一定是4kB对齐的。体会这种通过把最低位置零来实现内存对齐的算法。如果我们把高位看做页的编号了，那么低12位就可以表示在一个特定页面内部的偏移量。

我们说Sv32是32位宽处理器特有的，32位宽处理器指的是CPU在做普通的数学运算、内存访问的时候，能计算的数最大是32bit的，但是由于内存地址翻译功能的存在，我们相当于让CPU核心与外面的内存中间加了一个中间层。CPU核心运算单元能看到的内存地址总是32bit的，但它实际访问的物理内存地址经过翻译可能超过32bit。

这也就是说，在32bit的RISC-V处理器上，如果开启了内存地址翻译功能，那么每一个进程仍然只能访问自己的4GB内存空间，这个不变。但是可以接到这个CPU芯片上的内存颗粒，可以达到16GB的总大小，也就是说所有运行的进程加起来，他们可以使用的内存最大可以到16GB。

但是啊，这个也要看芯片的生产厂商为实际的一款芯片留出了多少根地址线，因为芯片的引脚数量是有限的，生产商在生产的时候，不一定会把34根地址信号线都引出芯片，假设一款芯片引出了34根地址线，那么这款芯片最大可以连接的物理内存就是16GB，但是你在设计一块主板的时候，虽然最大可以有16GB，但是你的板子上可能只放了1GB的内存颗粒，这样就相当于你实际只使用了30根地址信号线。同样，有的厂商因为芯片引脚有限，可能只引出了28根信号线出来，那这样就限定了这款芯片能访问的物理内存最大不超过256MB。

回忆一下前面我们逐步演进设计页表存储结构的时候，我们设计的每一个页表项里存储的都是一个地址，这个地址都指向一个4kB对齐的物理内存。因为指向的位置都是4kB对齐的，所以地址的低12位一定都是0，如果不利用起来实在是一种浪费，所以我们可以看到在RISC-V的实现中，每一个页表项的低12位被用来存储了许多额外标志位，这些标志位可以让我们的内存翻译功能更加强大。

我们一位一位来看，从最低位开始看起：

+ V标志位，表明这个PTE是否可用，我们是在一个4k页里面连续分配了1024个PTE，这1024个PTE就像一个数组，虽然每次都会预分配1024个PTE，但不一定每一个PTE都是被用到的，通过这个标志位可以让我们方便的判断一个PTE是否空闲。在分配内存时，可以查找V=0的PTE，对应的就是可用的空闲内存。

+ XWR三个比特位分别用于表示这个页表项所指向的内存区域的访问权限。
    + 同时这3个bit还有另一重用途，就是用来在多级页表的树形结构中判断这个节点是中间节点还是叶子节点。如果这三个比特位都是0，那么他就是一个中间节点，这个PTE指向的物理内存上存储的是下一级页表，如果不是全0的，那么这就是叶子节点，PTE指向的物理内存就是真正要分配给应用使用的内存地址。
    + 叶子节点和非叶子节点的PTE格式完全一样
    + 如果应用程序试图访问没有权限访问的内存，会导致处理器Trap

+ U标志位设置这个页面是否可以在U特权态中被访问，U=0表示U特权态不能访问，U=1表示这个页属于U特权态，U态可以访问。
    + 对于U=1的页面，S态是否可以访问取决于sstatus寄存器中的SUM标志位，出于安全考虑，通常情况下S态是无权访问U=1的页面。
+ G标志位用于表示这个页面是否在所有的地址空间中共享，对于一些需要在所有地址空间共享的内存，设置G=1可以降低页表切换过程中的开销。但是如果对不能共享的内存设置了G=1，则是一个软件上的BUG。如果你不能确定G=1可以使用，那就不要设置G=1。

+ A表示自从上一次清零该比特位之后，如果对应的内存区域有过读、写或者取指令操作，那么标记为1
+ D表示自从上一次清零该比特位之后，如果对应的内存区域有过写操作，那么标记为1
+ RSW是两个保留位，无意义

上面已经介绍了和页表项有关的知识，我们已经知道了一个页表的树形结构是什么样子了。接下来看一下如何实现在多个进程之间切换页表。我们已经说过，每一个进程都有自己的页表，每个页表都是一棵树，每棵树都有一个树根，这个树根也是一个大小为4kB的内存区域。我们只要知道了这个4k页面的首地址，就相当于知道了整个页表。

于是，在RISC-V里面，S态引入了一个叫做satp的寄存器，老样子，s表示这个寄存器属于S态，atp是Address Translation and Protection的简写，翻译过来就是“地址翻译和保护”,从前面页表项的内容也可以知道，页表项里即包含了用于把VA翻译成PA的必要信息，又包含了每个内存页的读、写、执行权限，所以页表既能实现翻译，也能实现保护功能。

我们看一下特权级规范的4.1.11小节，这里分别给出了32bit和64bit处理器上satp寄存器的位域描述。中间的ASID部分我们不管，看首尾，最低位部分是PPN（Physical Page Number），也就是一个指向物理地址上某个4k页的指针。这个4k页显然就是我们之前说的页表根节点所在的4k页。这样，我们说的切换页表的过程，实际就是修改这个satp寄存器中PPN位域的过程，让它指向不同的页表根节点即可。而satp寄存器的高位是一个模式选择位，从这里可以选择是使用Sv39还是其他的虚拟地址格式。

所以，一圈看下来，我们上面说了那么多的内容，其实都在介绍页表在内存里是怎么存储的。而真正到了和虚拟内存有关CSR寄存器的时候，竟然只有一个简简单单的satp寄存器。


再来提一嘴MMU（Memory Management Unit），MMU的作用就是以硬件电路的形式来实现上面介绍的查表过程。也就是说页表数据结构的建立和维护，是需要我们写软件来实现的，但是这个表的主要使用者是一个硬件。

接下来开始解决开头的3个问题，第一个问题，就是页表最基础的作用，应该不用再多说了。

第二个问题，页表如何帮助实现COW。答案其实也不难，当进行fork的时候，操作系统会把父进程的页表项都设置为只读权限，并且把父进程的页表项复制一份给子进程，这样子进程与父进程其实共享的都是同一块物理内存。（两个进程各自的VA映射到同一块PA上），这样，我们就不用去复制整个父进程的内存地址给到子进程了。无论父进程还是子进程，只要不进行写操作，那就什么事都没有，而一旦进行写操作，因为现在父子进程的页面都改为只读了，所以会触发一个异常，从U态陷入S态，操作系统这个时候接管过来执行权，根据异常的原因发现这是要修改共享的内存，于是就可以重新分配一个页给到子进程，然后把子进程对应的页表项指向新分配的这块内存空间，然后就可以把这块内存在父子进程中的权限都改为可读可写，然后再返回用户态。我们之前也提到过中断和异常的区别，异常是有确定的指令触发的，比如这里的异常就是尝试修改共享内存的那条指令导致的，在trap处理结束后，会重新跳回到导致异常的指令上去，也就是重试这个指令。这次重试的时候，因为已经有权限访问这块内存了，所以从应用程序的视角来看，就像什么都没发生过一样。通过这种方式，我们就实现了COW，以4kB为最小单位，用多少内存复制多少内存。

第三个问题，mmap的实现，也是通过设置页表权限，引发异常，然后做一番操作。比如用户要把硬盘上的某个文件的一段映射到内存的某个地址区间里面去，那么就先在页表项里把这一段VA对应的内存映射到一块物理内存上，然后把硬盘文件中对应的数据加载到物理内存对应的区域里面去。如果要映射的文件很小，那是可以一次性把磁盘文件都读到内存里面去的，但是如果映射的文件体积很大，甚至硬盘上文件的大小可能超过物理内存的大小，这个时候，我们可以先在VA空间里把整个文件对应的内存地址都先分配好页表，但是不指向具体的物理内存，同时设置读写权限，当程序访问内存的时候，同样是陷入，然后操作系统根据读写的地址把硬盘文件对应的区块加载到内存里面，然后再修改页表，这样就可以实现通过读取内存的形式来读取文件了。那么如果是写内存呢？如果你对文件映射到的内存区间有写操作，对应页表项的D标志位会被置1，操作系统中会有一个后台线程定期检测哪些页表是脏的，再把这些脏的页刷回到磁盘上去。